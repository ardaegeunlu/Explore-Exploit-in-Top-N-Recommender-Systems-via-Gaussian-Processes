function [item_choices, observations, oracle_observations] = CGPRank(kernel, GP_hyperparameters,...
    batch_size, T, context_receiver_handle, available_item_list_receiver_handle, ...
    feedback_handle, calculate_optimal_rewards, t_feedback_delay, feedback_delay_growth_ratio, t_approximation)


%% Parse optional arguments
if ~(exist('t_feedback_delay', 'var') & exist('feedback_delay_growth_ratio', 'var'))
    % time to start feedback_delay is not set, so feedback will not be
    % delayed.
    disp('time to start feedback_delay or feedback delay growth ratio is not set, so feedback will not be delayed.')
    t_feedback_delay = T + 1;
else
    disp('Feedback delaying is active.')
end

if ~exist('t_approximation', 'var')
    % time to start approximated gaussian inferences is not set, so feedback will not be
    % delayed.
    disp('Approximate solutions for GP Inference will not be used.')
    t_approximation = T + 1;
else
    disp('Approximate solutions for GP Inference are active.')
end

if ~exist('calculate_optimal_rewards', 'var')
    % optimal values will not be observed.
    disp('Optimal rewards will not be observed.')
    calculate_optimal_rewards = false;
else
    disp('Optimal rewards are being observed.')
end

%% Initialize required variables
covfunc = kernel;

item_choices = [];
observations = [];
oracle_observations = zeros(T,1);

% this is for delaying feedback
last_feedback_update = 0;

%% Execute for T rounds
for t = 1:T
    %% Round 1 has no data for inference, so randomized selection is applied.
    % round 1 requires a random initializations as there are no
    % observations, or choices for GP inference
    if t == 1
        
        % get context and available items for round 1
        available_items = available_item_list_receiver_handle(t)';
        context = context_receiver_handle(t);
        
        % do random sampling of size=batch_size to choose items
        random_item_choices = datasample(available_items, batch_size, 'Replace', false);
        % pair chosen items with the context at round 1
        chosen_item_context_pairs = [random_item_choices, repmat(context, size(random_item_choices))];
        % initialize chosen_items set with these pairs
        item_choices = chosen_item_context_pairs;
        % receive feedback
        feedback = feedback_handle(random_item_choices', repmat(context, size(random_item_choices')));
        observations = [observations, feedback];
        if calculate_optimal_rewards
            oracle_observations(t) = GetOracleChoices(available_items, context, batch_size, feedback_handle);
        end
        % continue to round 2.
        continue
    end
    %% 
    % get context at round t
    context = context_receiver_handle(t);
    % get the list of available items at round t
    available_items = available_item_list_receiver_handle(t)';
    
    % create a temp observations array, delay feedback if t>t_feedback_delay and if
    % there is not a feedback_delay_growth_ratio size improvement on
    % observation's size
    if t < t_feedback_delay
        % dont delay feedback 
        item_choices_stub = item_choices;
        observations_stub = observations;
        last_feedback_update = t;
    elseif (t - last_feedback_update) > last_feedback_update * feedback_delay_growth_ratio
        % feedback_delay_growth_ratio improvement on the observations, update again
        item_choices_stub = item_choices;
        observations_stub = observations;
        last_feedback_update = t;
    else
        % delay feedback
        item_choices_stub = item_choices(1:last_feedback_update*batch_size,:);
        observations_stub = observations(1:last_feedback_update*batch_size,:);
    end
    
    % there will be #'batch_size' recommendations at each round
    recommendations = [];
    
    % pair available items with the context at round t
    item_context_pairs = [available_items, repmat(context, size(available_items))];
    % get oracle's reward, to compute regret
    if calculate_optimal_rewards
        oracle_observations(t) = GetOracleChoices(available_items, context, batch_size, feedback_handle);
    end
    for item = 1:batch_size
        
        % GP Inference, refer to GPInference function below
        if t > t_approximation
            % the number of inducing inputs is the factor that determines
            % speed of GPSparseCovRegression, feel free to play with it.
            
            number_of_inducing_inputs = batch_size*t_approximation + sqrt(t - t_approximation)* batch_size;
            if number_of_inducing_inputs > size(item_choices_stub, 2)
                number_of_inducing_inputs = size(item_choices_stub, 2);
            end
            
            [predictive_mean, predictive_var] = GPSparseCovRegression(GP_hyperparameters, covfunc, ...
                item_choices_stub, observations_stub, item_context_pairs, number_of_inducing_inputs);
        else
            [predictive_mean, predictive_var] = GPInference(GP_hyperparameters, covfunc, ...
                item_choices_stub, observations_stub, item_context_pairs);
        end
        
        % Apply UCB Selection rule, refer to function below.
        chosen_item = UCBSelectionRule(predictive_mean, predictive_var, t);
        recommended_item = item_context_pairs(chosen_item,:);
        
        % do updates
        
        recommendations = [recommendations, available_items(chosen_item)'];
        item_choices_stub = [item_choices_stub; recommended_item];
        observations_stub = [observations_stub; predictive_mean(chosen_item)];
        
        % remove chosen_item from pairs, so that it is not chosen multiple
        % times
        item_context_pairs(chosen_item, :) = [];
        available_items(chosen_item, :) = [];
    end
    
    % get feedback at the end, update real observations array
    feedback = feedback_handle(recommendations, repmat(context, size(recommendations)));
    item_choices = [item_choices; item_choices_stub(end-batch_size+1:end,:)];
    observations = [observations; feedback];
    disp(['at round ',num2str(t),'.'])
    
end

end

%% Gaussian Process Regression with Gaussian Likelihood (Direct Inference)

function [predictive_mean, predictive_var] = GPInference(GP_hyperparameters, covfunc, X, Y, inference_points)
    
    % no mean function, you can change this depending on the application
    meanfunc = [];
    % direct inference, no approximation
    likfunc = @likGauss;
    GP_hyperparameters.lik = log(0.1);
    % hyp2 = minimize(GP_hyperparameters, @gp, -100, @infGaussLik, meanfunc, covfunc, likfunc, X, Y);
    [predictive_mean, predictive_var] = gp(GP_hyperparameters, @infGaussLik, meanfunc, covfunc, likfunc, ...
        X, Y, inference_points);
end

%% Approximate Regression with Sparse Covariance Approximations

function [predictive_mean, predictive_var] = GPSparseCovRegression(GP_hyperparameters, covfunc, X, Y, inference_points, inducing_input_n)
    
    % no mean function, you can change this depending on the application
    meanfunc = [];
    
    % Equidistant inducing points, does not give good results these tests..
    if size(X, 2) == 2 & false
        n = uint8(sqrt(inducing_input_n));
        minX = min(X, [], 1);
        maxX = max(X, [], 1);
        x1_space = linspace(minX(1), maxX(1), n);
        x2_space = linspace(minX(2), maxX(2), n);
        [x1mesh, x2mesh] = meshgrid(x1_space, x2_space);
        u = [x1mesh(:) x2mesh(:)];
    else
    
        % choose inducing inputs randomly from all the points seen so far, this
        % is admittedly not the optimal way to choose these points.
        inducing_input_n = uint8(inducing_input_n);
        u = datasample(X, inducing_input_n, 'Replace', false);
    end
    
    covfuncApprox = {@apxSparse, covfunc, u};
    
    likfunc = @likGauss;
    GP_hyperparameters.lik = log(0.1);
    inf = @(varargin) infGaussLik(varargin{:}, struct('s', 0.0));
    
    [predictive_mean, predictive_var] = gp(GP_hyperparameters, inf, meanfunc, covfuncApprox, likfunc, ...
        X, Y, inference_points);
end

%% Upper-Confidence-Bound Selection Rule that optimizes explore-exploit tradeoff

function [index] = UCBSelectionRule(predictive_mean, predictive_var, t)
    beta = beta_selector(t);
    [~, index] = max(predictive_mean + sqrt(beta*predictive_var));
end

%% Selection of Beta

function beta = beta_selector(t)
    % simplified tradeoff from the paper
    C = 1.0;
    d = -2.0;
    beta = C * power(log(t), d);
end

%% Oracle's Best Possible Observations
% Useful to plot regret and other relevant statistics.

function [best_possible_reward] = GetOracleChoices(available_items, context, batch_size, feedback_handle)
    feedback = feedback_handle(available_items, repmat(context', size(available_items)));
    max_elements = maxk(feedback, batch_size);
    best_possible_reward = sum(max_elements);
end
